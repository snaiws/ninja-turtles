{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32af0822",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 227\u001b[0m\n\u001b[1;32m    225\u001b[0m original_data_dir \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#Target_Data './Compete_Dataset_Refined/'\u001b[39;00m\n\u001b[1;32m    226\u001b[0m new_data_dir \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#New Dir './Compete_COCO/'\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m \u001b[43mcreate_new_data_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m avg_iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(iou_scores) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(iou_scores)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage IoU between img vs polygon: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_iou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m, in \u001b[0;36mcreate_new_data_directory\u001b[0;34m(original_data_dir, new_data_dir, split_ratio)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_new_data_directory\u001b[39m(original_data_dir, new_data_dir, split_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Ensure the new data directory exists\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(new_data_dir):\n\u001b[0;32m---> 10\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Define paths for images and labels\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     new_images_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(new_data_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import uuid\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def create_new_data_directory(original_data_dir, new_data_dir, split_ratio=0.8):\n",
    "    # Ensure the new data directory exists\n",
    "    if not os.path.exists(new_data_dir):\n",
    "        os.makedirs(new_data_dir)\n",
    "\n",
    "    # Define paths for images and labels\n",
    "    new_images_dir = os.path.join(new_data_dir, 'images')\n",
    "    new_labels_dir = os.path.join(new_data_dir, 'labels')\n",
    "\n",
    "    # Ensure the new directories for images and labels exist\n",
    "    for subdir in ['train']:\n",
    "        os.makedirs(os.path.join(new_images_dir, subdir), exist_ok=True)\n",
    "        os.makedirs(os.path.join(new_labels_dir, subdir), exist_ok=True)\n",
    "\n",
    "    # List all image files and corresponding label files for train and val sets\n",
    "    def list_files(base_dir, split_type):\n",
    "        image_files = []\n",
    "        label_files = []\n",
    "        for cityname in os.listdir(base_dir):\n",
    "            img_dir = os.path.join(base_dir, cityname, 'img')\n",
    "            label_dir = os.path.join(base_dir, cityname, 'new_txt')\n",
    "            if os.path.exists(img_dir) and os.path.exists(label_dir):\n",
    "                for img_file in os.listdir(img_dir):\n",
    "                    if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        image_files.append(os.path.join(img_dir, img_file))\n",
    "                        label_file = os.path.join(label_dir, os.path.splitext(img_file)[0] + '.txt')\n",
    "                        if os.path.exists(label_file):\n",
    "                            label_files.append(label_file)\n",
    "        return list(zip(image_files, label_files))\n",
    "\n",
    "    train_files = list_files(os.path.join(original_data_dir, 'train'), 'train')\n",
    "\n",
    "    # Copy files and rename them uniquely\n",
    "    def copy_and_rename_files(files, split_type):\n",
    "        txt_file_path = os.path.join(new_data_dir, f'{split_type}.txt')\n",
    "        with open(txt_file_path, 'w') as txt_file:\n",
    "            for image_path, label_path in files:\n",
    "                #unique_id = uuid.uuid4().hex\n",
    "                unique_id = os.path.splitext(image_path)[0].split('/')[-3]+'_'+os.path.splitext(image_path)[0].split('/')[-1]\n",
    "                \n",
    "                # Copy image file\n",
    "                img_ext = os.path.splitext(image_path)[1]\n",
    "                new_image_name = f'{unique_id}{img_ext}'\n",
    "                dest_image_path = os.path.join(new_images_dir, split_type, new_image_name)\n",
    "                shutil.copy(image_path, dest_image_path)\n",
    "\n",
    "                # Copy and reformat label file\n",
    "                new_label_name = f'{unique_id}.txt'\n",
    "                dest_label_path = os.path.join(new_labels_dir, split_type, new_label_name)\n",
    "                reformat_label_file(label_path, dest_label_path, image_path)\n",
    "\n",
    "                # Write new image path to txt file\n",
    "                txt_file.write(dest_image_path + '\\n')\n",
    "\n",
    "    def calculate_iou(mask1, mask2):\n",
    "        intersection = np.logical_and(mask1, mask2).sum()\n",
    "        union = np.logical_or(mask1, mask2).sum()\n",
    "        return intersection / union if union != 0 else 0\n",
    "    def recreate_mask_from_polygons(polygons, size):\n",
    "        mask = np.zeros(size, dtype=np.uint8)\n",
    "        for polygon in polygons:\n",
    "            contour = np.array(polygon).reshape((-1, 2))\n",
    "            cv2.fillPoly(mask, [contour], 255)\n",
    "        return mask\n",
    "    def remove_noise(mask):\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        return mask\n",
    "    # Reformat the label file to include instance segmentation mask coordinates\n",
    "    def reformat_label_file(src_label_path, dest_label_path, image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        mask_dir = os.path.join(os.path.dirname(image_path), '..', 'instance')\n",
    "        mask_path = os.path.join(mask_dir, os.path.basename(image_path))\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        with open(src_label_path, 'r') as src_file:\n",
    "            lines = src_file.readlines()\n",
    "        with open(dest_label_path, 'w') as dest_file:\n",
    "            line_num = 0\n",
    "            writen_line = 0\n",
    "            for line in lines:\n",
    "                line_num+=1\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 10:\n",
    "                    x1, y1, x2, y2, class_id, loc_id, brake, incatlft, incatrht, hazlit = map(float, parts[:10])\n",
    "\n",
    "                    # Extract the mask for the current instance\n",
    "                    instance_mask = np.zeros_like(mask)\n",
    "                    instance_mask[mask == int(line_num)] = 255\n",
    "                    new_instance_mask = remove_noise(instance_mask)\n",
    "                    \n",
    "                    polygons = mask2polygon(new_instance_mask,cv2.CHAIN_APPROX_NONE)\n",
    "                    len_polygons=0\n",
    "                    for pp in polygons:\n",
    "                        len_polygons += len(pp)\n",
    "                    '''\n",
    "                    if len_polygons>200:\n",
    "                        # Use the provided mask2polygon method to convert mask to polygons\n",
    "                        polygons = mask2polygon(new_instance_mask)\n",
    "                    '''\n",
    "                    \n",
    "                    # Recreate mask from polygons\n",
    "                    recreated_mask = recreate_mask_from_polygons(polygons, instance_mask.shape)\n",
    "                    \n",
    "                    # Calculate IoU between original and recreated mask\n",
    "                    iou_score = calculate_iou(instance_mask, recreated_mask)\n",
    "                    iou_scores.append(iou_score)\n",
    "                    if iou_score>0.01:\n",
    "                        normalized_contours = []\n",
    "                        for polygon in polygons:\n",
    "                            normalized_contours.extend([(polygon[i] / width if i % 2 == 0 else polygon[i] / height) for i in range(len(polygon))])\n",
    "                        if len(normalized_contours)==0:\n",
    "                            pass\n",
    "                        else:\n",
    "                            # Write to destination label file in the desired format\n",
    "                            new_label_line = f'{int(class_id)} {int(loc_id)} {int(brake)} {int(incatlft)} {int(incatrht)} {int(hazlit)} ' + ' '.join(map(str, normalized_contours))\n",
    "                            dest_file.write(new_label_line + '\\n')\n",
    "                            writen_line+=1\n",
    "                else:\n",
    "                    print(parts)\n",
    "    # Process train and val sets\n",
    "\n",
    "    copy_and_rename_files(train_files, 'train')\n",
    "\n",
    "# Use the mask2polygon function provided in the initial code\n",
    "def mask2polygon(image, mode=cv2.CHAIN_APPROX_TC89_KCOS ):\n",
    "    contours, hierarchies = cv2.findContours(image, cv2.RETR_CCOMP, mode)\n",
    "    contours_approx = []\n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        epsilon = 0.001 * cv2.arcLength(contour, True)\n",
    "        contour_approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        contours_approx.append(contour_approx)\n",
    "\n",
    "    contours_parent = []\n",
    "    for i, contour in enumerate(contours_approx):\n",
    "        parent_idx = hierarchies[0][i][3]\n",
    "        if parent_idx < 0 and len(contour) >= 3:\n",
    "            contours_parent.append(contour)\n",
    "        else:\n",
    "            contours_parent.append([])\n",
    "\n",
    "    for i, contour in enumerate(contours_approx):\n",
    "        parent_idx = hierarchies[0][i][3]\n",
    "        if parent_idx >= 0 and len(contour) >= 3:\n",
    "            contour_parent = contours_parent[parent_idx]\n",
    "            if len(contour_parent) == 0:\n",
    "                continue\n",
    "            contours_parent[parent_idx] = merge_with_parent(contour_parent, contour)\n",
    "\n",
    "    contours_parent_tmp = []\n",
    "    for contour in contours_parent:\n",
    "        if len(contour) == 0:\n",
    "            continue\n",
    "        contours_parent_tmp.append(contour)\n",
    "\n",
    "    polygons = []\n",
    "    for contour in contours_parent_tmp:\n",
    "        polygon = contour.flatten().tolist()\n",
    "        polygons.append(polygon)\n",
    "    return polygons \n",
    "\n",
    "# Use the provided helper functions for merging contours\n",
    "def is_clockwise(contour):\n",
    "    value = 0\n",
    "    num = len(contour)\n",
    "    for i, point in enumerate(contour):\n",
    "        p1 = contour[i]\n",
    "        if i < num - 1:\n",
    "            p2 = contour[i + 1]\n",
    "        else:\n",
    "            p2 = contour[0]\n",
    "        value += (p2[0][0] - p1[0][0]) * (p2[0][1] + p1[0][1])\n",
    "    return value < 0\n",
    "\n",
    "def get_merge_point_idx(contour1, contour2):\n",
    "    idx1 = 0\n",
    "    idx2 = 0\n",
    "    distance_min = -1\n",
    "    for i, p1 in enumerate(contour1):\n",
    "        for j, p2 in enumerate(contour2):\n",
    "            distance = (p2[0][0] - p1[0][0]) ** 2 + (p2[0][1] - p1[0][1]) ** 2\n",
    "            if distance_min < 0:\n",
    "                distance_min = distance\n",
    "                idx1 = i\n",
    "                idx2 = j\n",
    "            elif distance < distance_min:\n",
    "                distance_min = distance\n",
    "                idx1 = i\n",
    "                idx2 = j\n",
    "    return idx1, idx2\n",
    "\n",
    "def merge_contours(contour1, contour2, idx1, idx2):\n",
    "    contour = []\n",
    "    for i in range(0, idx1 + 1):\n",
    "        contour.append(contour1[i])\n",
    "    for i in range(idx2, len(contour2)):\n",
    "        contour.append(contour2[i])\n",
    "    for i in range(0, idx2 + 1):\n",
    "        contour.append(contour2[i])\n",
    "    for i in range(idx1, len(contour1)):\n",
    "        contour.append(contour1[i])\n",
    "    contour = np.array(contour)\n",
    "    return contour\n",
    "\n",
    "def merge_with_parent(contour_parent, contour):\n",
    "    if not is_clockwise(contour_parent):\n",
    "        contour_parent = contour_parent[::-1]\n",
    "    if is_clockwise(contour):\n",
    "        contour = contour[::-1]\n",
    "    idx1, idx2 = get_merge_point_idx(contour_parent, contour)\n",
    "    return merge_contours(contour_parent, contour, idx1, idx2)\n",
    "\n",
    "iou_scores = []\n",
    "# Example usage\n",
    "original_data_dir ='' #Target_Data './Compete_Dataset_Refined/'\n",
    "new_data_dir ='' #New Dir './Compete_COCO/'\n",
    "create_new_data_directory(original_data_dir, new_data_dir, split_ratio=0.8)\n",
    "\n",
    "avg_iou = sum(iou_scores) / len(iou_scores)\n",
    "print(f\"Average IoU between img vs polygon: {avg_iou}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdd4f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
