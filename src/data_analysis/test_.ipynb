{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/miniconda3/envs/tld/bin/python\n",
      "Python version: 3.8.20 | packaged by conda-forge | (default, Sep 30 2024, 17:48:42) \n",
      "[Clang 17.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "load_dotenv(verbose = False)\n",
    "DIR_MODEL = os.getenv(\"DIR_MODEL\")\n",
    "sys.path.append(\"/Users/hunew/Desktop/Python_Files/Projects/Project_2(CV-Autonomous_driving)/EDA_test/ninja-turtles/src/machine/OD/ultralytics\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  41%|████      | 5497/13502 [14:31<20:49,  6.41image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hunew/Desktop/Python_Files/02_Storage/Project_2(CV-Autonomous_driving)/Data/test/predictions/10005495.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  41%|████      | 5500/13502 [14:32<20:46,  6.42image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hunew/Desktop/Python_Files/02_Storage/Project_2(CV-Autonomous_driving)/Data/test/predictions/10005498.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  43%|████▎     | 5783/13502 [15:19<19:50,  6.48image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hunew/Desktop/Python_Files/02_Storage/Project_2(CV-Autonomous_driving)/Data/test/predictions/10005781.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  43%|████▎     | 5790/13502 [15:21<19:46,  6.50image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hunew/Desktop/Python_Files/02_Storage/Project_2(CV-Autonomous_driving)/Data/test/predictions/10005788.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 13502/13502 [37:08<00:00,  6.06image/s]\n"
     ]
    }
   ],
   "source": [
    "def get_file_extension(filename):\n",
    "    _, extension = os.path.splitext(filename)\n",
    "    return extension.lstrip('.')\n",
    "\n",
    "\n",
    "test_db_path = \"/Users/hunew/Desktop/Python_Files/02_Storage/Project_2(CV-Autonomous_driving)/Data/test\"\n",
    "test_res_path = \"%s/predictions\"%(test_db_path)\n",
    "\n",
    "if not os.path.exists(test_res_path):\n",
    "    os.makedirs(test_res_path)\n",
    "\n",
    "img_exts = [\"jpg\",\"bmp\",\"png\"]\n",
    "img_files = list()\n",
    "for img_ext in img_exts:\n",
    "    img_files += glob.glob(\"%s/images/*.%s\"%(test_db_path, img_ext))\n",
    "\n",
    "img_files.sort() \n",
    "\n",
    "model_filename = \"/Users/hunew/Desktop/Python_Files/02_Storage/Project_2(CV-Autonomous_driving)/Models/tld-Baseline/best.pt\"\n",
    "model = YOLO(model_filename)\n",
    "\n",
    "# Check if MPS is available and set the device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "for img_filename in tqdm(img_files, desc=\"Processing images\", unit=\"image\", leave=True):\n",
    "    result = model.predict(img_filename, imgsz=1280, conf=0.001, iou=0.6, device=device, verbose = False)[0]\n",
    "\n",
    "    img_ext = get_file_extension(img_filename)\n",
    "    txt_filename = img_filename.replace(img_ext, \"txt\")\n",
    "    txt_filename = txt_filename.replace(\"images\", \"predictions\")\n",
    "    boxes = result.boxes \n",
    "    num_obj = len(boxes.cls)\n",
    "\n",
    "    with open(txt_filename, 'w') as f1:\n",
    "        for obj_idx in range(num_obj):\n",
    "            cls_id = int(boxes.cls[obj_idx])\n",
    "            cs = boxes.conf[obj_idx]\n",
    "            xywhn = boxes.xywhn[obj_idx]\n",
    "            # class_id norm_center_x norm_center_y norm_w norm_h confidence_score\n",
    "            f1.write(\"%d %lf %lf %lf %lf %lf\\n\" % (cls_id, xywhn[0], xywhn[1], xywhn[2], xywhn[3], cs))\n",
    "\n",
    "    if num_obj == 0:\n",
    "        print(txt_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
